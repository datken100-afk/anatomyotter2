
import { GoogleGenAI, Type, Schema, GenerateContentResponse } from "@google/genai";
import { Difficulty, GeneratedMCQResponse, GeneratedStationResponse, MentorResponse, StationItem } from "../types";

// L·∫•y API Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (Vercel Environment Variable)
const apiKey = process.env.API_KEY || '';

// Initialize Gemini Client
const ai = new GoogleGenAI({ apiKey });

// UPGRADE: Use Gemini 3 Pro for superior reasoning
const MODEL_MCQ = "gemini-3-pro-preview";
const MODEL_VISION = "gemini-2.5-flash"; // Updated from 1.5 to 2.5
const MODEL_CHAT = "gemini-2.5-flash";

interface ContentFile {
    content: string;
    isText: boolean;
}

// Token Limits
const LIMIT_THEORY_CHARS = 2400000; 
const LIMIT_CLINICAL_CHARS = 1000000; 
const LIMIT_SAMPLE_CHARS = 200000; 

// --- RETRY LOGIC HELPER ---
const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function retryGeminiCall<T>(
  call: () => Promise<T>,
  retries: number = 3,
  initialDelay: number = 2000
): Promise<T> {
  let lastError: any;
  
  for (let i = 0; i < retries; i++) {
    try {
      return await call();
    } catch (error: any) {
      lastError = error;
      
      // Check for common API errors
      const isRateLimit = 
        error.status === 429 || 
        error.status === 503 ||
        (error.message && (
          error.message.includes("429") || 
          error.message.includes("quota") || 
          error.message.includes("RESOURCE_EXHAUSTED") ||
          error.message.includes("Overloaded")
        ));

      // Check for Model Not Found (404) - Usually due to old code or region lock
      if (error.status === 404 || (error.message && error.message.includes("not found"))) {
          console.error("Model Not Found Error. Please check if you are using the latest code and a valid API Key.");
          throw new Error(`L·ªói Model AI (${error.status}): Kh√¥ng t√¨m th·∫•y Model. Vui l√≤ng Redeploy code m·ªõi nh·∫•t l√™n Vercel.`);
      }

      if (isRateLimit) {
        if (i === retries - 1) break; 
        console.warn(`Gemini Rate Limit hit. Retrying in ${initialDelay}ms... (Attempt ${i + 1}/${retries})`);
        await wait(initialDelay);
        initialDelay *= 2; 
      } else {
        throw error; 
      }
    }
  }
  
  const cleanMsg = lastError?.message || "Unknown error";
  if (cleanMsg.includes("quota") || cleanMsg.includes("RESOURCE_EXHAUSTED")) {
      throw new Error("ƒê√£ h·∫øt h·∫°n m·ª©c s·ª≠ d·ª•ng AI (Quota Exceeded). Vui l√≤ng ki·ªÉm tra g√≥i c∆∞·ªõc ho·∫∑c th·ª≠ l·∫°i v√†o ng√†y mai.");
  }
  throw new Error(`L·ªói k·∫øt n·ªëi AI: ${cleanMsg}`);
}

export const generateMCQQuestions = async (
  topic: string,
  count: number,
  difficulties: Difficulty[],
  files: { theory?: ContentFile[]; clinical?: ContentFile[]; sample?: ContentFile[] } = {}
): Promise<GeneratedMCQResponse> => {
  if (!apiKey) throw new Error("Ch∆∞a c·∫•u h√¨nh API Key. Vui l√≤ng th√™m API_KEY v√†o Vercel Environment Variables.");

  let systemInstruction = `
    B·∫°n l√† m·ªôt gi√°o s∆∞ Y khoa h√†ng ƒë·∫ßu. Nhi·ªám v·ª• c·ªßa b·∫°n l√† t·∫°o ƒë·ªÅ thi tr·∫Øc nghi·ªám gi·∫£i ph·∫´u h·ªçc ch·∫•t l∆∞·ª£ng cao.
    
    QUY T·∫ÆC PH√ÇN T√çCH T√ÄI LI·ªÜU (TU√ÇN TH·ª¶ TUY·ªÜT ƒê·ªêI):
    1. D·ªÆ LI·ªÜU L√ù THUY·∫æT (Theory): CH·ªà ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√°c c√¢u h·ªèi thu·ªôc m·ª©c ƒë·ªô: 
       - ${Difficulty.REMEMBER} (Ghi nh·ªõ)
       - ${Difficulty.UNDERSTAND} (Hi·ªÉu)
       - ${Difficulty.APPLY} (V·∫≠n d·ª•ng th·∫•p)

    2. D·ªÆ LI·ªÜU L√ÇM S√ÄNG (Clinical): CH·ªà ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√¢u h·ªèi m·ª©c ƒë·ªô:
       - ${Difficulty.CLINICAL} (L√¢m s√†ng/Ca b·ªánh)
       C√¢u h·ªèi l√¢m s√†ng b·∫Øt bu·ªôc ph·∫£i l√† c√°c Case Study (t√¨nh hu·ªëng b·ªánh nh√¢n) c·ª• th·ªÉ.

    3. ƒê·ªÄ THI M·∫™U: N·∫øu c√≥, h√£y h·ªçc phong c√°ch ƒë·∫∑t c√¢u h·ªèi v√† format t·ª´ ƒë√≥.

    C·∫§U TR√öC ƒê·ªÄ THI:
    - T·ªïng s·ªë c√¢u: ${count} c√¢u.
    - Ch·ªß ƒë·ªÅ: "${topic}".
    - C√°c m·ª©c ƒë·ªô kh√≥ y√™u c·∫ßu: ${difficulties.join(', ')}.
    - M·ªói c√¢u h·ªèi c√≥ 4 l·ª±a ch·ªçn, 1 ƒë√°p √°n ƒë√∫ng.
    - Gi·∫£i th√≠ch: Ph·∫£i c·ª±c k·ª≥ chi ti·∫øt, tr√≠ch d·∫´n l√Ω do t·∫°i sao ƒë√∫ng/sai.
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      questions: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            question: { type: Type.STRING },
            options: { type: Type.ARRAY, items: { type: Type.STRING } },
            correctAnswer: { type: Type.STRING },
            explanation: { type: Type.STRING },
            difficulty: { type: Type.STRING },
          },
          required: ["question", "options", "correctAnswer", "explanation", "difficulty"],
        },
      },
    },
    required: ["questions"],
  };

  const parts: any[] = [];

  const addContentParts = (fileItems: ContentFile[] | undefined, sectionTitle: string, usageInstruction: string, charLimit: number) => {
    if (!fileItems || fileItems.length === 0) return;

    parts.push({ text: `\n=== B·∫ÆT ƒê·∫¶U PH·∫¶N: ${sectionTitle} ===\nCH·ªà D·∫™N: ${usageInstruction}\n` });
    
    let currentChars = 0;

    for (const item of fileItems) {
        if (currentChars >= charLimit) {
             parts.push({ text: `\n[C·∫¢NH B√ÅO: ƒê√£ ng∆∞ng t·∫£i th√™m t√†i li·ªáu ph·∫ßn n√†y do v∆∞·ª£t qu√° gi·ªõi h·∫°n b·ªô nh·ªõ cho ph√©p]\n` });
             break;
        }

        if (item.content) {
            if (item.isText) {
                let textToAdd = item.content;
                const remaining = charLimit - currentChars;

                if (textToAdd.length > remaining) {
                    textToAdd = textToAdd.substring(0, remaining) + "\n\n[...N·ªôi dung file n√†y ƒë√£ b·ªã c·∫Øt b·ªõt do gi·ªõi h·∫°n b·ªô nh·ªõ AI...]";
                }
                
                parts.push({ text: `\n--- FILE CONTENT ---\n${textToAdd}\n` });
                currentChars += textToAdd.length;
            } else {
                const base64Data = item.content.includes('base64,') ? item.content.split('base64,')[1] : item.content;
                parts.push({
                    inlineData: {
                        mimeType: "application/pdf", 
                        data: base64Data
                    }
                });
                currentChars += 50000; 
            }
        }
    }
    parts.push({ text: `=== K·∫æT TH√öC PH·∫¶N: ${sectionTitle} ===\n` });
  };

  addContentParts(files.theory, "T√ÄI LI·ªÜU L√ù THUY·∫æT", `D√πng cho c√¢u h·ªèi m·ª©c ƒë·ªô th·∫•p.`, LIMIT_THEORY_CHARS);
  addContentParts(files.clinical, "T√ÄI LI·ªÜU L√ÇM S√ÄNG", `CH·ªà D√πng cho c√¢u h·ªèi m·ª©c ƒë·ªô ${Difficulty.CLINICAL}.`, LIMIT_CLINICAL_CHARS);
  addContentParts(files.sample, "ƒê·ªÄ THI M·∫™U", "Tham kh·∫£o c√°ch ƒë·∫∑t c√¢u h·ªèi.", LIMIT_SAMPLE_CHARS);

  parts.push({ text: `H√£y "Suy nghƒ©" (Thinking) k·ªπ v·ªÅ ph√¢n ph·ªëi c√¢u h·ªèi, sau ƒë√≥ so·∫°n th·∫£o ${count} c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªÅ ch·ªß ƒë·ªÅ "${topic}" theo ƒë√∫ng ƒë·ªãnh d·∫°ng JSON ƒë√£ y√™u c·∫ßu.` });

  try {
    console.log(`Generating MCQs with model: ${MODEL_MCQ}`);
    const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
      model: MODEL_MCQ,
      contents: { parts: parts },
      config: {
        systemInstruction: systemInstruction,
        responseMimeType: "application/json",
        responseSchema: schema,
        thinkingConfig: { thinkingBudget: 2048 }, 
      },
    }));

    let text = response.text;
    if (!text) throw new Error("No response from AI");
    
    const jsonBlockMatch = text.match(/```json\s*([\s\S]*?)\s*```/);
    if (jsonBlockMatch) {
        text = jsonBlockMatch[1];
    } else {
        text = text.replace(/```json/g, '').replace(/```/g, '');
    }
    
    text = text.trim();
    const parsed = JSON.parse(text);

    if (!parsed || typeof parsed !== 'object' || !Array.isArray(parsed.questions)) {
       throw new Error("Invalid response structure");
    }

    return parsed as GeneratedMCQResponse;

  } catch (error: any) {
    console.error("Gemini API Error:", error);
    if (error.message && (error.message.includes("qu√° t·∫£i") || error.message.includes("h·∫øt h·∫°n m·ª©c") || error.message.includes("Redeploy"))) {
        throw error;
    }
    if (error.message && error.message.includes("token count exceeds")) {
        throw new Error("T·ªïng dung l∆∞·ª£ng t√†i li·ªáu qu√° l·ªõn. Vui l√≤ng b·ªõt file.");
    }
    throw error;
  }
};

// --- Generate Spot Test Question from Image (Vision) ---
export interface StationQuestionResponse {
    isValid: boolean;
    questions?: {
        questionText: string;
        correctAnswer: string;
        explanation: string;
    }[];
}

export const generateStationQuestionFromImage = async (base64Image: string, topic?: string): Promise<StationQuestionResponse> => {
    if (!apiKey) throw new Error("Ch∆∞a c·∫•u h√¨nh API Key.");
    
    const systemInstruction = `
    B·∫°n l√† gi√°m kh·∫£o thi ch·∫°y tr·∫°m (Spot Test) Gi·∫£i ph·∫´u h·ªçc c·ª±c k·ª≥ nghi√™m t√∫c.
    
    NHI·ªÜM V·ª§ 1: KI·ªÇM TRA T√çNH H·ª¢P L·ªÜ & ƒê√öNG CH·ª¶ ƒê·ªÄ: "${topic || 'Gi·∫£i ph·∫´u h·ªçc'}".
    - H√¨nh ·∫£nh H·ª¢P L·ªÜ: H√¨nh gi·∫£i ph·∫´u r√µ r√†ng, c√≥ ch√∫ th√≠ch/leader lines, ƒê√öNG CH·ª¶ ƒê·ªÄ.
    - H√¨nh ·∫£nh KH√îNG H·ª¢P L·ªÜ: To√†n ch·ªØ, M·ª•c l·ª•c, Sai ch·ªß ƒë·ªÅ.

    NHI·ªÜM V·ª§ 2: RA ƒê·ªÄ (N·∫øu H·ª£p l·ªá):
    1. Ch·ªçn M·ªòT c·∫•u tr√∫c gi·∫£i ph·∫´u quan tr·ªçng nh·∫•t trong h√¨nh LI√äN QUAN ƒê·∫æN CH·ª¶ ƒê·ªÄ.
    2. ƒê·∫∑t c√¢u h·ªèi ƒë·ªãnh danh tr·ª±c ti·∫øp (VD: "Chi ti·∫øt s·ªë 1 l√† g√¨?").
    3. ƒê√°p √°n Ti·∫øng Vi·ªát ch√≠nh x√°c.

    Output JSON format: { "isValid": boolean, "questions": [...] }
    `;

    const prompt = topic 
        ? `Ki·ªÉm tra xem h√¨nh n√†y c√≥ ch·ª©a c·∫•u tr√∫c gi·∫£i ph·∫´u thu·ªôc ch·ªß ƒë·ªÅ "${topic}" kh√¥ng. N·∫øu c√≥, h√£y t·∫°o 1 c√¢u h·ªèi tr·∫°m.` 
        : "Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† h√¨nh gi·∫£i ph·∫´u h·ª£p l·ªá kh√¥ng. N·∫øu c√≥, h√£y t·∫°o 1 c√¢u h·ªèi tr·∫°m.";

    try {
        const cleanBase64 = base64Image.includes('base64,') ? base64Image.split('base64,')[1] : base64Image;
        
        console.log(`Generating Station with model: ${MODEL_VISION}`);
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model: MODEL_VISION,
            contents: { 
                role: 'user', 
                parts: [
                    { text: prompt },
                    { inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } }
                ] 
            },
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        isValid: { type: Type.BOOLEAN },
                        questions: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.OBJECT,
                                properties: {
                                    questionText: { type: Type.STRING },
                                    correctAnswer: { type: Type.STRING },
                                    explanation: { type: Type.STRING }
                                },
                                required: ["questionText", "correctAnswer", "explanation"]
                            }
                        }
                    },
                    required: ["isValid"]
                }
            }
        }));

        let text = response.text || "";
        text = text.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(text) as StationQuestionResponse;
    } catch (e: any) {
        console.error("Vision API Error", e);
        if (e.message && (e.message.includes("qu√° t·∫£i") || e.message.includes("quota") || e.message.includes("429") || e.message.includes("Redeploy"))) {
            throw e;
        }
        return { isValid: false, questions: [] };
    }
};

export const analyzeResultWithOtter = async (
    topic: string,
    stats: Record<string, { correct: number, total: number }>
): Promise<MentorResponse> => {
    if (!apiKey) return { analysis: "Ch∆∞a c√≥ API Key", strengths: [], weaknesses: [], roadmap: [] };

    const statsDescription = Object.entries(stats)
        .map(([diff, val]) => {
             const pct = val.total > 0 ? Math.round((val.correct / val.total) * 100) : 0;
             return `- ${diff}: ${val.correct}/${val.total} c√¢u (${pct}%)`;
        })
        .join('\n');

    const prompt = `
    ƒê√≥ng vai l√† "R√°i c√° nh·ªè" ü¶¶ - gia s∆∞ AI gi·∫£i ph·∫´u.
    H·ªçc vi√™n v·ª´a l√†m b√†i thi ch·ªß ƒë·ªÅ: "${topic}".
    D·ªÆ LI·ªÜU: \n${statsDescription}
    
    NHI·ªÜM V·ª§:
    1. Ph√¢n t√≠ch nƒÉng l·ª±c.
    2. Ch·ªâ ra ƒêi·ªÉm m·∫°nh/Y·∫øu.
    3. L·ªô tr√¨nh c·∫£i thi·ªán (4 b∆∞·ªõc c·ª• th·ªÉ, k·ªπ thu·∫≠t h·ªçc t·∫≠p r√µ r√†ng).
    
    JSON Output: { "analysis": string, "strengths": string[], "weaknesses": string[], "roadmap": [{ "step": string, "details": string }] }
    `;

    try {
        console.log(`Analyzing with model: ${MODEL_MCQ}`);
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model: MODEL_MCQ,
            contents: { role: 'user', parts: [{ text: prompt }] },
            config: {
                responseMimeType: "application/json",
                thinkingConfig: { thinkingBudget: 2048 }
            }
        }));

        let text = response.text || "";
        text = text.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(text) as MentorResponse;
    } catch (e) {
        console.error(e);
        return {
            analysis: "√öi cha! R√°i c√° ƒëang b·∫≠n b·∫Øt c√° n√™n kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c r·ªìi. Th·ª≠ l·∫°i sau nh√©! ü¶¶",
            strengths: [],
            weaknesses: [],
            roadmap: []
        };
    }
};

export const chatWithOtter = async (history: {role: 'user' | 'model', text: string, image?: string}[], message: string, image?: string): Promise<string> => {
    if (!apiKey) return "Vui l√≤ng nh·∫≠p API Key ƒë·ªÉ chat v·ªõi R√°i c√°!";

    const systemInstruction = `B·∫°n l√† "R√°i c√° nh·ªè" (Little Otter) ü¶¶ - tr·ª£ l√Ω ·∫£o GI·∫¢I PH·∫™U H·ªåC.
    - Vui v·∫ª, chuy√™n nghi·ªáp, d√πng emoji ü¶¶ ü¶¥ üß†.
    - Gi·∫£i ƒë√°p ki·∫øn th·ª©c gi·∫£i ph·∫´u, ph√¢n t√≠ch h√¨nh ·∫£nh.
    - Tr√¨nh b√†y Markdown g·ªçn g√†ng.
    `;

    const contents = history.map(msg => {
        const parts: any[] = [{ text: msg.text }];
        if (msg.image) {
             try {
                 const base64Data = msg.image.includes('base64,') ? msg.image.split('base64,')[1] : msg.image;
                 const mimeType = msg.image.match(/data:([^;]+);base64,/)?.[1] || 'image/jpeg';
                 parts.push({ inlineData: { mimeType, data: base64Data }});
             } catch (e) { console.warn("History image error", e); }
        }
        return { role: msg.role, parts };
    });

    const currentParts: any[] = [{ text: message }];
    if (image) {
        try {
            const base64Data = image.includes('base64,') ? image.split('base64,')[1] : image;
            const mimeType = image.match(/data:([^;]+);base64,/)?.[1] || 'image/jpeg';
            currentParts.push({ inlineData: { mimeType, data: base64Data }});
        } catch (e) { console.warn("Current image error", e); }
    }
    contents.push({ role: 'user', parts: currentParts });

    try {
        console.log(`Chatting with model: ${MODEL_CHAT}`);
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model: MODEL_CHAT,
            contents,
            config: { systemInstruction }
        }));
        return response.text || "R√°i c√° ƒëang b∆°i ƒëi ƒë√¢u m·∫•t r·ªìi... ü¶¶";
    } catch (e) {
        console.error(e);
        return "√öi! M·∫°ng b·ªã ngh·∫Ωn ho·∫∑c l·ªói k·∫øt n·ªëi. B·∫°n h·ªèi l·∫°i nh√©? ü¶¶";
    }
};
